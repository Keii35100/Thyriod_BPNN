# Imports
import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error

# Read dataset
data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cl_thyroid_conditions.csv')

# Change class label to binary
data["target_sick"] = data["target_sick"].astype('category')
data["target_sick_bin"] = data["target_sick"].cat.codes
data["sex=M"] = data["sex=M"].astype(float)

# Suffle data
cl_data = np.array(data.drop(['target_sick'], axis=1), dtype = float)
m, n = cl_data.shape
np.random.shuffle(cl_data)

persentage_split = 80/100

# Assign input and output
train_data = cl_data[0: int(m*persentage_split)].T
X_train = train_data[0:-1].T                      # (412, 7)
Y_train = np.expand_dims(train_data[-1], axis=-1) # (412, 1)

row, col = train_data.shape

#X_test = 
#Y_test = 

# Activation function
def sigmoid(s):               # Get Zj and Yk
    return 1 / (1 + np.exp(-s))

# Derivative of sigmoid
def sigmoid_derivative(sd):    # Get dk and dj
    return sd * (1 - sd)

# Class definition
class NeuralNetwork:
    def __init__(self, X_train, Y_train):
        self.input = X_train                  # (412, 7)
        self.w1 = np.random.rand(row-1, 7)    # (7, 7)    7 nodes in hidden layer
        self.w2 = np.random.rand(7, 1)        # (7, 1)    1 node in output layer
        self.y  = Y_train                     # (412, 1)
        self.target = np.zeros(Y_train.shape) # (412, 1)
        self.alpha  = 0.1
        
    def feedforward(self):
        self.layer1 = sigmoid(np.dot(self.input, self.w1))    # (412, 7) layer1 = Zj - step 4 
        self.layer2 = sigmoid(np.dot(self.layer1, self.w2))   # (412, 1) layer2 = Yk - step 5 
        return self.layer2
        
    def backprop(self):
        self.dk = np.dot(np.abs((self.target - self.y.T)), sigmoid_derivative(self.layer2)) # (412, 1) - step 6
        self.d_w2 = np.dot(self.alpha, np.dot(self.dk.T, self.layer2))                      # (1, 1)   - step 6

        self.dj_in = np.dot(self.dk, self.w2.T)                                             # (412, 7) - step 7
        self.dj = np.dot(self.dj_in.T, sigmoid_derivative(self.layer1))                     # (7, 7)   - step 7
        self.d_w1 = np.dot(self.alpha, np.dot(self.dj, self.input.T))                       # (7, 412) - step 7
        #print("d_w1: ", self.d_w1.shape)
        #print("Y:::", np.info(self.target))

    def update_param(self):
        #print("dw1:::", np.info(self.d_w1))
        self.w1 += self.d_w1
        self.w2 += self.d_w2

    def train(self, X_train, Y_train):
        self.target = self.feedforward()
        self.backprop()
        self.update_param()

NN = NeuralNetwork(X_train, Y_train)
#print (Y_train, NN.target)
for i in range(10): # trains the NN 1000 times
    #print ("for iteration # " + str(i) + "\n")
    #print ("Loss: \n" + str(mean_squared_error(y, NN.feedforward()))) # mean sum squared loss
    #print ("Accuracy: \n" + str(100 - (np.mean(np.square(y - NN.feedforward()))).astype(float))) # mean sum squared loss
    print ("\n.")
  
NN.train(X_train, Y_train)
