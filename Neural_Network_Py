# imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score

# read dataset
data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cl_thyroid_conditions.csv')

# suffle data
cl_data = np.array(data)
m, n = cl_data.shape
np.random.shuffle(cl_data)                          # shuffle data
train_data = cl_data.T

# assign input and output
X_train = train_data[0:n-1].T                        # get input train data
Y_train = np.expand_dims(train_data[-1], axis=-1)   # get output train data

# activation function
# sigmoid function
def sigmoid(x):                                     # Get Zj and Yk
    return 1 / (1 + np.exp(-x))

# derivative of sigmoid
def sigmoid_deriv(x):                         # Get dk and dj
    return x * (1 - x)

def __init__(X_train, Y_train, alpha):
    X   = np.array(X_train)                     # input
    Y   = np.array(Y_train)                     # output
    A   = alpha                                 # learning rate
    W1  = np.random.rand(n-1, 10) - 0.5         # nodes in hidden layer
    W2  = np.random.rand(10, 1) - 0.5           # nodes in output layer
    b1  = np.random.rand(10, 1)
    b2  = np.random.rand(10, 1)
    return X, Y, A, W1, W2, b1, b2
        
def feedforward(X, Y, W1, W2, b1, b2):
    Z1_in = X.dot(W1)
    Z1 = sigmoid(Z1_in)

    Z2_in = Z1.dot(W2)
    Z2 = sigmoid(Z2_in)
    #print("Z1_in:", Z1_in.shape, "Z1:", Z1.shape, "Z2_in:", Z2_in.shape, "Z2:", Z2.shape) 
    return Z1_in, Z1, Z2_in, Z2

def backprop(Z1_in, Z1, Z2_in, Z2, W1, W2, X, Y):
    dZ2_in = Y - Z2
    dZ2 = dZ2_in * sigmoid_deriv(Z2)
    #print("dZ2_in:", dZ2_in.shape, "dZ2:", dZ2.shape)

    dZ1_in = dZ2.dot(W2.T)
    dZ1 = dZ1_in * sigmoid_deriv(Z1)
    #print("dZ1_in:", dZ1_in.shape, "dZ1:", dZ1.shape)

    dW2 = Z1.T.dot(dZ2) / m
    dW1 = X.T.dot(dZ1) / m
    #print("dW2:", dW2.shape, "dW1:", dW1.shape)
    return dZ2, dZ1, dW2, dW1

def update_param(W1, W2, dW2, dW1, A):
    W2 += dW2 * A
    W1 += dW1 * A
    #print("W2:", W2.shape, "W1:", W1.shape)
    return W1, W2                                

def __MAIN__(X_train, Y_train, alpha, epoch):
    X, Y, A, W1, W2, b1, b2 = __init__(X_train, Y_train, alpha)
    #results = pd.DataFrame(columns=["mse", "accuracy"])
    for i in range(epoch):
        Z1_in, Z1, Z2_in, Z2 = feedforward(X, Y, W1, W2, b1, b2)
        dZ2, dZ1, dW2, dW1 = backprop(Z1_in, Z1, Z2_in, Z2, W1, W2, X, Y)
        W1, W2 = update_param(W1, W2, dW2, dW1, A)
        mse = mean_squared_error(Y_train, Z2)
        #acc = accuracy(Y_train, Z2)
        #results = results.append({"mse":mse, "accuracy":acc},ignore_index=True )
        if (i % 10 == 0):
            print("Iteration: ", i)
            #print("dW1:", dW1[1:4], "\ndW2:", dW2[1:4].T)
            #print("Z1:", Z1[1:4], "\nZ2:", Z2[1:4].T)
            print("Loss: ", mse)
            print("Accuracy:", (1-mse)*100)
            print("\n")

__MAIN__(X_train, Y_train, 0.2, 5000)
